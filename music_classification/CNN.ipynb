{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "535019aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import io\n",
    "import IPython\n",
    "from scipy import signal\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from util import *\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e30baf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageSplitter:\n",
    "    \n",
    "    def __init__(self,\n",
    "                ax = 1,\n",
    "                split_along = 1,\n",
    "                split_size_0 = 2,\n",
    "                split_size_1 = 2):\n",
    "        self.ax = ax\n",
    "        self.split_along = split_along\n",
    "        self.split_size_0 = split_size_0\n",
    "        self.split_size_1 = split_size_1\n",
    "    \n",
    "    def get_image_params(self, image):\n",
    "        _0, _1 = image.shape\n",
    "        if (_0 % self.split_size_0 != 0) or (_1 % self.split_size_1 != 0):\n",
    "            raise Exception(\"Can't split image to desired size\")\n",
    "        return _0, _1, int(_0 / self.split_size_0), int(_1 / self.split_size_1)\n",
    "    \n",
    "    def split_along_one(self, image):\n",
    "        _0, _1, s_0, s_1 = self.get_image_params(image)\n",
    "        if self.ax == 0:\n",
    "            s = s_0\n",
    "        else:\n",
    "            s = s_1\n",
    "        return np.array(np.split(image, s, axis=self.ax))\n",
    "    \n",
    "    def split_along_two(self, image):\n",
    "        _0, _1, s_0, s_1 = self.get_image_params(image)\n",
    "        q = []\n",
    "        for i in np.split(image, s_0, axis=0):\n",
    "            q.append(np.split(i, s_1, axis=1))\n",
    "        q = np.array(q)\n",
    "        return q.reshape(-1, self.split_size_0, self.split_size_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d1eb1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample rate is:22050\n"
     ]
    }
   ],
   "source": [
    "# Build library of all songs (10 genres, 100 songs each)\n",
    "catalogue = build_catalogue()\n",
    "library = build_library(catalogue, c_type='list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55eaed0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {k:v for k, v in zip(range(10), catalogue.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8be9d472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim all tracks to n=660000 samples and convert to numpy array. Will have dimensions (10, 100, 660000).\n",
    "a = []\n",
    "for n, i in enumerate(library):\n",
    "    s = []\n",
    "    for j in i:\n",
    "        s.append(j[:660000])\n",
    "    library[n] = s\n",
    "library = np.array(library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bda7759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some utility functions to select and downsaple tunes:\n",
    "def select_tune(genre, tune_n, library, genre_cat = genres):\n",
    "    genres = {k:v for k, v in zip(genre_cat, range(10))}\n",
    "    return library[genres[genre]][tune_n]\n",
    "\n",
    "def down_sample_tune(tune, dsr=5):\n",
    "    ds_sample = tune.reshape(-1, dsr).mean(axis=1).flatten()\n",
    "    return ds_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2d5a5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now use all available tracks for all genres:\n",
    "songs = []\n",
    "for i in library:\n",
    "    for j in i:\n",
    "        ds_tune = down_sample_tune(j, dsr=5)\n",
    "        f, t, Sxx = signal.spectrogram(ds_tune, fs=22050 / 5, nperseg=1024, window='hanning')\n",
    "        Sxx[Sxx == 0] = 1\n",
    "        s = (10 * np.log10(Sxx))\n",
    "        songs.append(s)\n",
    "songs = np.array(songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "bd4e785e",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_s = ImageSplitter(split_size_0=260, split_size_1=73)\n",
    "songs_mod = []\n",
    "for im in songs[:, :260, :146]:\n",
    "    songs_mod.append(im_s.split_along_two(im))\n",
    "songs_mod = np.array(songs_mod).reshape(-1, 260, 73)[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9ed6dfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.repeat(np.arange(10), 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b0cdbccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_FULL, X_test_FULL, y_train_FULL, y_test_FULL = train_test_split(songs_mod, labels, test_size=0.3, random_state=42)\n",
    "X_train, X_valid = X_train_FULL[:1200], X_train_FULL[1200:]\n",
    "y_train, y_valid = y_train_FULL[:1200], y_train_FULL[1200:]\n",
    "\n",
    "x_mean = X_train.mean()\n",
    "x_std = X_train.std()\n",
    "X_train = (X_train - x_mean) / x_std\n",
    "X_valid = (X_valid - x_mean) / x_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0254b42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DefaultConv2D = partial(keras.layers.Conv2D,\n",
    "                        kernel_size=3, activation='relu', padding=\"SAME\")\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    DefaultConv2D(filters=16, kernel_size=3, input_shape=[260, 73, 1]),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    DefaultConv2D(filters=32),\n",
    "    DefaultConv2D(filters=32),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    DefaultConv2D(filters=64),\n",
    "    DefaultConv2D(filters=64),\n",
    "    keras.layers.MaxPooling2D(pool_size=4),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(units=64, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(units=32, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(units=10, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "246b6819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_60 (Conv2D)           (None, 260, 73, 16)       160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 130, 36, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 130, 36, 32)       4640      \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 130, 36, 32)       9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 65, 18, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 65, 18, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_64 (Conv2D)           (None, 65, 18, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 16, 4, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 64)                262208    \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 334,090\n",
      "Trainable params: 334,090\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "89a62325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "38/38 [==============================] - 7s 187ms/step - loss: 2.3018 - accuracy: 0.0983 - val_loss: 2.2500 - val_accuracy: 0.2250\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 7s 190ms/step - loss: 2.2586 - accuracy: 0.1275 - val_loss: 2.1981 - val_accuracy: 0.1750\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 8s 200ms/step - loss: 2.2251 - accuracy: 0.1475 - val_loss: 2.1473 - val_accuracy: 0.2550\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 8s 208ms/step - loss: 2.2062 - accuracy: 0.1608 - val_loss: 2.1239 - val_accuracy: 0.2600\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 8s 209ms/step - loss: 2.1996 - accuracy: 0.1658 - val_loss: 2.0846 - val_accuracy: 0.2750\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 8s 208ms/step - loss: 2.1806 - accuracy: 0.1908 - val_loss: 2.0386 - val_accuracy: 0.2350\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 8s 207ms/step - loss: 2.1846 - accuracy: 0.1958 - val_loss: 2.0614 - val_accuracy: 0.2850\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 8s 208ms/step - loss: 2.1895 - accuracy: 0.1858 - val_loss: 2.1096 - val_accuracy: 0.2800\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 8s 208ms/step - loss: 2.1626 - accuracy: 0.1975 - val_loss: 2.0187 - val_accuracy: 0.2600\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 8s 212ms/step - loss: 2.1525 - accuracy: 0.2050 - val_loss: 2.0043 - val_accuracy: 0.2900\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ebc4e256",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6236af9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1320011 , 0.13955067, 0.10709064, 0.08561222, 0.06417766,\n",
       "       0.16635914, 0.06488865, 0.06474456, 0.1046022 , 0.07097319],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e5b1000c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076895bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7314d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1923c2b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff16a7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
    "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]\n",
    "\n",
    "X_mean = X_train.mean(axis=0, keepdims=True)\n",
    "X_std = X_train.std(axis=0, keepdims=True) + 1e-7\n",
    "X_train = (X_train - X_mean) / X_std\n",
    "X_valid = (X_valid - X_mean) / X_std\n",
    "X_test = (X_test - X_mean) / X_std\n",
    "\n",
    "X_train = X_train[..., np.newaxis]\n",
    "X_valid = X_valid[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdea47f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "DefaultConv2D = partial(keras.layers.Conv2D,\n",
    "                        kernel_size=3, activation='relu', padding=\"SAME\")\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    DefaultConv2D(filters=32, kernel_size=7, input_shape=[28, 28, 1]),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    DefaultConv2D(filters=64),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    DefaultConv2D(filters=128),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(units=64, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(units=32, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(units=10, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a737b9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 28, 28, 32)        1600      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                73792     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 170,154\n",
      "Trainable params: 170,154\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d57a6a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 29s 16ms/step - loss: 0.8825 - accuracy: 0.6883 - val_loss: 0.4387 - val_accuracy: 0.8308\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 30s 18ms/step - loss: 0.5694 - accuracy: 0.8035 - val_loss: 0.3416 - val_accuracy: 0.8750\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 30s 17ms/step - loss: 0.4968 - accuracy: 0.8304 - val_loss: 0.3376 - val_accuracy: 0.8802\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 30s 17ms/step - loss: 0.4557 - accuracy: 0.8456 - val_loss: 0.3136 - val_accuracy: 0.8872\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 30s 17ms/step - loss: 0.4227 - accuracy: 0.8587 - val_loss: 0.3218 - val_accuracy: 0.8878\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 30s 17ms/step - loss: 0.4041 - accuracy: 0.8634 - val_loss: 0.3082 - val_accuracy: 0.8906\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 30s 17ms/step - loss: 0.3858 - accuracy: 0.8704 - val_loss: 0.3200 - val_accuracy: 0.8988\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 31s 18ms/step - loss: 0.3741 - accuracy: 0.8748 - val_loss: 0.2996 - val_accuracy: 0.8942\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 34s 20ms/step - loss: 0.3565 - accuracy: 0.8792 - val_loss: 0.2874 - val_accuracy: 0.8992\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 37s 21ms/step - loss: 0.3474 - accuracy: 0.8831 - val_loss: 0.3059 - val_accuracy: 0.9010\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95570cb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
